{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faca8a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.custom_dataset import YOLO6ChannelDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = YOLO6ChannelDataset(\n",
    "    left_img_dir=\"D:/intezet/Bogi/Yolo/data/images/train/left\",\n",
    "    right_img_dir=\"D:/intezet/Bogi/Yolo/data/images/train/right\",\n",
    "    label_dir=\"D:/intezet/Bogi/Yolo/data/labels/train\"\n",
    ")\n",
    "\n",
    "val_dataset = YOLO6ChannelDataset(\n",
    "    left_img_dir=\"D:/intezet/Bogi/Yolo/data/images/val/left\",\n",
    "    right_img_dir=\"D:/intezet/Bogi/Yolo/data/images/val/right\",\n",
    "    label_dir=\"dD:/intezet/Bogi/Yolo/data/labels/val\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f721722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=6\n",
      "WARNING no model scale passed. Assuming scale='n'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       896  ultralytics.nn.modules.conv.Conv             [6, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752482  ultralytics.nn.modules.head.Detect           [6, [64, 128, 256]]           \n",
      "YOLOv8 summary: 129 layers, 3,012,450 parameters, 3,012,434 gradients, 8.3 GFLOPs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds[0].shape = torch.Size([8, 70, 80, 80])\n",
      "preds[1].shape = torch.Size([8, 70, 40, 40])\n",
      "preds[2].shape = torch.Size([8, 70, 20, 20])\n",
      "loss: 576.159423828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   6%|â–Œ         | 1/17 [00:12<03:13, 12.07s/it, loss=576]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds[0].shape = torch.Size([8, 70, 80, 80])\n",
      "preds[1].shape = torch.Size([8, 70, 40, 40])\n",
      "preds[2].shape = torch.Size([8, 70, 20, 20])\n",
      "loss: 529.9642944335938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  12%|â–ˆâ–        | 2/17 [00:23<02:58, 11.90s/it, loss=530]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds[0].shape = torch.Size([8, 70, 80, 80])\n",
      "preds[1].shape = torch.Size([8, 70, 40, 40])\n",
      "preds[2].shape = torch.Size([8, 70, 20, 20])\n",
      "loss: 506.233154296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  18%|â–ˆâ–Š        | 3/17 [00:35<02:46, 11.87s/it, loss=506]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds[0].shape = torch.Size([8, 70, 80, 80])\n",
      "preds[1].shape = torch.Size([8, 70, 40, 40])\n",
      "preds[2].shape = torch.Size([8, 70, 20, 20])\n",
      "loss: 500.5117492675781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  24%|â–ˆâ–ˆâ–Ž       | 4/17 [00:46<02:27, 11.31s/it, loss=501]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds[0].shape = torch.Size([8, 70, 80, 80])\n",
      "preds[1].shape = torch.Size([8, 70, 40, 40])\n",
      "preds[2].shape = torch.Size([8, 70, 20, 20])\n",
      "loss: 496.559326171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  29%|â–ˆâ–ˆâ–‰       | 5/17 [00:56<02:10, 10.85s/it, loss=497]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds[0].shape = torch.Size([8, 70, 80, 80])\n",
      "preds[1].shape = torch.Size([8, 70, 40, 40])\n",
      "preds[2].shape = torch.Size([8, 70, 20, 20])\n",
      "loss: 492.3143615722656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 6/17 [01:02<01:44,  9.48s/it, loss=492]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds[0].shape = torch.Size([8, 70, 80, 80])\n",
      "preds[1].shape = torch.Size([8, 70, 40, 40])\n",
      "preds[2].shape = torch.Size([8, 70, 20, 20])\n",
      "loss: 490.2712097167969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 7/17 [01:08<01:23,  8.32s/it, loss=490]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds[0].shape = torch.Size([8, 70, 80, 80])\n",
      "preds[1].shape = torch.Size([8, 70, 40, 40])\n",
      "preds[2].shape = torch.Size([8, 70, 20, 20])\n",
      "loss: 487.094970703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 8/17 [01:14<01:06,  7.39s/it, loss=487]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds[0].shape = torch.Size([8, 70, 80, 80])\n",
      "preds[1].shape = torch.Size([8, 70, 40, 40])\n",
      "preds[2].shape = torch.Size([8, 70, 20, 20])\n",
      "loss: 484.9814453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 9/17 [01:20<00:57,  7.14s/it, loss=485]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds[0].shape = torch.Size([8, 70, 80, 80])\n",
      "preds[1].shape = torch.Size([8, 70, 40, 40])\n",
      "preds[2].shape = torch.Size([8, 70, 20, 20])\n",
      "loss: 483.2557678222656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 10/17 [01:26<00:47,  6.81s/it, loss=483]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds[0].shape = torch.Size([8, 70, 80, 80])\n",
      "preds[1].shape = torch.Size([8, 70, 40, 40])\n",
      "preds[2].shape = torch.Size([8, 70, 20, 20])\n",
      "loss: 480.7873229980469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 11/17 [01:32<00:38,  6.47s/it, loss=481]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds[0].shape = torch.Size([8, 70, 80, 80])\n",
      "preds[1].shape = torch.Size([8, 70, 40, 40])\n",
      "preds[2].shape = torch.Size([8, 70, 20, 20])\n",
      "loss: 479.1791076660156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 12/17 [01:38<00:31,  6.36s/it, loss=479]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds[0].shape = torch.Size([8, 70, 80, 80])\n",
      "preds[1].shape = torch.Size([8, 70, 40, 40])\n",
      "preds[2].shape = torch.Size([8, 70, 20, 20])\n",
      "loss: 476.82904052734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 13/17 [01:44<00:25,  6.25s/it, loss=477]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds[0].shape = torch.Size([8, 70, 80, 80])\n",
      "preds[1].shape = torch.Size([8, 70, 40, 40])\n",
      "preds[2].shape = torch.Size([8, 70, 20, 20])\n",
      "loss: 474.99615478515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 14/17 [01:50<00:18,  6.11s/it, loss=475]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds[0].shape = torch.Size([8, 70, 80, 80])\n",
      "preds[1].shape = torch.Size([8, 70, 40, 40])\n",
      "preds[2].shape = torch.Size([8, 70, 20, 20])\n",
      "loss: 473.0986022949219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 15/17 [01:55<00:11,  5.90s/it, loss=473]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds[0].shape = torch.Size([8, 70, 80, 80])\n",
      "preds[1].shape = torch.Size([8, 70, 40, 40])\n",
      "preds[2].shape = torch.Size([8, 70, 20, 20])\n",
      "loss: 472.5518798828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 16/17 [02:01<00:05,  5.67s/it, loss=473]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds[0].shape = torch.Size([7, 70, 80, 80])\n",
      "preds[1].shape = torch.Size([7, 70, 40, 40])\n",
      "preds[2].shape = torch.Size([7, 70, 20, 20])\n",
      "loss: 361.15185546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [02:06<00:00,  7.43s/it, loss=361]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“˜ Epoch 1 - Train Loss: 486.2317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mZeroDivisionError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 108\u001b[39m\n\u001b[32m    105\u001b[39m         loss_out = model.loss(preds, targets)\n\u001b[32m    106\u001b[39m         val_loss += loss_out[\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m].item()\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m avg_val_loss = \u001b[43mval_loss\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mðŸ§ª Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_val_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    111\u001b[39m \u001b[38;5;66;03m# --- Save ---\u001b[39;00m\n",
      "\u001b[31mZeroDivisionError\u001b[39m: float division by zero"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from ultralytics.nn.tasks import DetectionModel\n",
    "from types import SimpleNamespace\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from utils.custom_dataset import YOLO6ChannelDataset  # Assuming it's defined correctly\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 50\n",
    "batch_size = 8\n",
    "save_path = \"yolov8_custom6.pt\"\n",
    "\n",
    "\n",
    "# --- Collate Function ---\n",
    "def collate_fn(batch):\n",
    "    imgs, targets = zip(*batch)\n",
    "    imgs = torch.stack(imgs, dim=0)\n",
    "    targets_with_id = []\n",
    "    for i, t in enumerate(targets):\n",
    "        if t.numel() == 0:\n",
    "            continue\n",
    "        img_idx = torch.full((t.shape[0], 1), i, dtype=t.dtype)\n",
    "        targets_with_id.append(torch.cat([img_idx, t], dim=1))\n",
    "    if len(targets_with_id) == 0:\n",
    "        targets_combined = torch.zeros((0, 6))\n",
    "    else:\n",
    "        targets_combined = torch.cat(targets_with_id, dim=0)\n",
    "    # print(f\"targets_combined: {targets_combined}\")\n",
    "    return imgs, targets_combined\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                          collate_fn=collate_fn, num_workers=0)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
    "                        collate_fn=collate_fn, num_workers=0)\n",
    "\n",
    "\n",
    "# --- Model ---\n",
    "model = DetectionModel(cfg='ultralytics/cfg/models/v8/yolov8.yaml', ch=6, nc=6).to(device)\n",
    "model.args = SimpleNamespace(box=7.5, cls=0.5, dfl=1.5, reg_max=15)\n",
    "model.criterion = model.init_criterion()\n",
    "model.to(device)\n",
    "# print(f\"Expected output channels: {(model.args.reg_max + 1) * 4 + model.nc}\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# --- Training Loop ---\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "    \n",
    "    for imgs, targets in pbar:\n",
    "        # print(f\"imgs.shape: {imgs.shape}\")\n",
    "        imgs = imgs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        if targets.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(imgs)\n",
    "        if isinstance(preds, tuple) or isinstance(preds, list):\n",
    "            for i, p in enumerate(preds):\n",
    "                print(f\"preds[{i}].shape = {p.shape}\")\n",
    "        else:\n",
    "            print(f\"preds.shape = {preds.shape}\")\n",
    "\n",
    "        batch = {\n",
    "            \"img\": imgs,\n",
    "            \"batch_idx\": targets[:, 0],\n",
    "            \"cls\": targets[:, 1],\n",
    "            \"bboxes\": targets[:, 2:]\n",
    "        }\n",
    "        \n",
    "        loss, loss_items = model.loss(batch, preds)  # loss is scalar, loss_items is [box, cls, dfl]\n",
    "        loss = loss.sum()\n",
    "        print(f\"loss: {loss}\")\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"ðŸ“˜ Epoch {epoch+1} - Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, targets in val_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            if targets.shape[0] == 0:\n",
    "                continue\n",
    "\n",
    "            preds = model(imgs)\n",
    "            loss_out = model.loss(preds, targets)\n",
    "            val_loss += loss_out['loss'].item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"ðŸ§ª Epoch {epoch+1} - Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # --- Save ---\n",
    "    if (epoch + 1) % 5 == 0 or (epoch + 1) == epochs:\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"âœ… Model saved to: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d6a3f65",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'targets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mType of targets:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m(\u001b[43mtargets\u001b[49m))\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(targets, torch.Tensor):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mtargets.shape:\u001b[39m\u001b[33m\"\u001b[39m, targets.shape)\n",
      "\u001b[31mNameError\u001b[39m: name 'targets' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Type of targets:\", type(targets))\n",
    "if isinstance(targets, torch.Tensor):\n",
    "    print(\"targets.shape:\", targets.shape)\n",
    "    print(\"targets sample:\\n\", targets[:5])  # first 5 rows\n",
    "elif isinstance(targets, list):\n",
    "    print(\"targets is a list with length:\", len(targets))\n",
    "    print(\"First element type:\", type(targets[0]))\n",
    "    if isinstance(targets[0], torch.Tensor):\n",
    "        print(\"targets[0].shape:\", targets[0].shape)\n",
    "        print(\"targets[0] sample:\\n\", targets[0][:5])\n",
    "elif isinstance(targets, dict):\n",
    "    print(\"targets.keys():\", targets.keys())\n",
    "    for k, v in targets.items():\n",
    "        print(f\"{k}: type={type(v)}, shape={getattr(v, 'shape', 'N/A')}\")\n",
    "else:\n",
    "    print(\"Unknown targets format:\", targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
